# Kafka Order Processing System with Avro

A complete Kafka-based order processing system featuring Avro serialization, real-time aggregation, retry logic, and Dead Letter Queue (DLQ) handling.

## ğŸ¯ Features

- âœ… **Avro Serialization**: Schema-based message serialization using Apache Avro
- âœ… **Real-time Aggregation**: Running average calculation of order prices
- âœ… **Retry Logic**: Automatic retry mechanism for temporary failures (max 3 retries)
- âœ… **Dead Letter Queue**: Failed messages sent to DLQ after max retries exceeded
- âœ… **Schema Registry**: Centralized schema management
- âœ… **Kafka UI**: Web interface for monitoring topics and messages

## ğŸ“‹ Prerequisites

- Docker and Docker Compose
- Python 3.8+
- Git

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/MoraisMNS/kafka_assignment_4077
cd kafka-order-processing
```

### 2. Start Kafka Infrastructure

```bash
docker-compose up -d
```

This starts:
- Zookeeper (port 2181)
- Kafka Broker (port 9092)
- Schema Registry (port 8081)
- Kafka UI (port 8080)

**Verify services are running:**
```bash
docker-compose ps
```

### 3. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the System

**Terminal 1 - Start Consumer:**
```bash
python consumer.py
```

**Terminal 2 - Start Producer:**
```bash
python producer.py
```

## ğŸ“Š Monitoring

Access Kafka UI at: http://localhost:8080

Here you can:
- View topics (`orders` and `orders-dlq`)
- Monitor messages in real-time
- Check consumer groups
- View schemas in the registry

## ğŸ—ï¸ Architecture

```
Producer â†’ Kafka Topic (orders) â†’ Consumer
                                      â†“
                                  Processing
                                      â†“
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â†“                           â†“
                   Success                       Failure
                        â†“                           â†“
                  Aggregation                  Retry Logic
                        â†“                           â†“
                  Commit Offset           Max Retries Exceeded?
                                                    â†“
                                          Dead Letter Queue (DLQ)
```

## ğŸ“‚ Project Structure

```
kafka-order-processing/
â”œâ”€â”€ order.avsc              # Avro schema definition
â”œâ”€â”€ producer.py             # Message producer
â”œâ”€â”€ consumer.py             # Message consumer with retry & DLQ
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ docker-compose.yml      # Kafka infrastructure
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Configuration

### Producer Configuration
- **Bootstrap Servers**: localhost:9092
- **Topic**: orders
- **Serialization**: Avro with Schema Registry

### Consumer Configuration
- **Bootstrap Servers**: localhost:9092
- **Topic**: orders
- **Group ID**: order-consumer-group
- **Max Retries**: 3
- **Retry Delay**: 2 seconds
- **Window Size**: 10 (for running average)
- **Auto Offset Reset**: earliest

### Avro Schema
```json
{
  "type": "record",
  "name": "Order",
  "namespace": "com.orderprocessing",
  "fields": [
    {"name": "orderId", "type": "string"},
    {"name": "product", "type": "string"},
    {"name": "price", "type": "float"}
  ]
}
```

## ğŸ® How It Works

### Producer
1. Generates random order messages with orderId, product, and price
2. Serializes messages using Avro format
3. Sends to Kafka topic `orders`
4. Reports delivery status

### Consumer
1. Subscribes to `orders` topic
2. Deserializes Avro messages
3. Processes each order:
   - **Success**: Updates running average and commits offset
   - **Failure**: Retries up to 3 times with 2-second delay
   - **Max Retries Exceeded**: Sends to DLQ topic
4. Maintains real-time statistics:
   - Running average (last 10 orders)
   - Overall average
   - Total orders processed
   - Total revenue

### Real-time Aggregation
- Maintains a sliding window of the last 10 prices
- Calculates running average
- Tracks overall average across all processed orders
- Displays statistics after each successful processing

### Retry Logic
- Automatically retries failed messages up to 3 times
- 2-second delay between retries
- Tracks retry count per order ID
- Resets count on successful processing

### Dead Letter Queue
- Failed messages sent to `orders-dlq` topic after max retries
- Includes original order, error message, retry count, and timestamp
- Allows for later analysis and reprocessing

## ğŸ“ˆ Sample Output

**Producer:**
```
ğŸš€ Starting to produce 20 orders...

ğŸ“¦ Producing order: {'orderId': '1000', 'product': 'Lipstick', 'price': 899.99}
âœ… Message delivered to orders [0] at offset 0
```

**Consumer:**
```
ğŸ¯ Consumer started. Waiting for messages...

âœ… Processed: Order 1000 | Product: Lipstick | Price: Rs.899.99
   ğŸ“Š Running Avg: Rs.899.99 | Overall Avg: Rs.899.99 | Total Orders: 1

âš ï¸  Processing error: Processing failed for order 1001
ğŸ”„ Retry 1/3 for order 1001
âœ… Processed: Order 1001 | Product: Foundation | Price: $699.50
   ğŸ“Š Running Avg: Rs.799.75 | Overall Avg: Rs.799.75 | Total Orders: 2

ğŸ’€ Sent to DLQ: Order 1002 after 3 retries
```

## ğŸ§ª Testing

### Test Retry Logic
The consumer simulates a 20% failure rate. Run both producer and consumer to see:
- Successful processing
- Automatic retries
- DLQ messages

### View DLQ Messages
```bash
# Using Kafka UI (http://localhost:8080)
# Navigate to: Topics â†’ orders-dlq â†’ Messages
```

### Manual Testing
Modify the failure rate in `consumer.py`:
```python
if random.random() < 0.2:  # Change to 0.5 for 50% failure rate
    raise Exception(f'Processing failed for order {order_id}')
```

## ğŸ› ï¸ Troubleshooting

### Services not starting
```bash
docker-compose down
docker-compose up -d
```

### Check service logs
```bash
docker-compose logs kafka
docker-compose logs schema-registry
```

### Reset Kafka data
```bash
docker-compose down -v
docker-compose up -d
```

### Python dependency issues
```bash
pip install --upgrade pip
pip install -r requirements.txt --force-reinstall
```

## ğŸ“ Key Concepts Demonstrated

1. **Avro Serialization**: Efficient binary format with schema evolution
2. **Schema Registry**: Centralized schema management and versioning
3. **Consumer Groups**: Parallel processing with offset management
4. **At-least-once Delivery**: Manual offset commit after successful processing
5. **Error Handling**: Graceful degradation with retry and DLQ patterns
6. **Real-time Processing**: Stream processing with stateful aggregation

## ğŸ“ Assignment Requirements

âœ… Kafka-based system with producer and consumer  
âœ… Avro serialization with schema  
âœ… Real-time aggregation (running average)  
âœ… Retry logic for temporary failures  
âœ… Dead Letter Queue for permanent failures  
âœ… Live demonstration capability  
âœ… Git repository with documentation  

## ğŸ”— Useful Resources

- [Confluent Kafka Python](https://docs.confluent.io/kafka-clients/python/current/overview.html)
- [Apache Avro](https://avro.apache.org/docs/)
- [Kafka Schema Registry](https://docs.confluent.io/platform/current/schema-registry/index.html)
- [Kafka UI](https://docs.kafka-ui.provectus.io/)

## ğŸ“§ Support

For issues or questions:
1. Check Kafka UI for message flow
2. Review logs: `docker-compose logs`
3. Verify Python dependencies are installed
4. Ensure all ports are available (2181, 8080, 8081, 9092)

## ğŸ‰ Success Criteria

Your system is working correctly when you see:
- âœ… Messages produced successfully
- âœ… Messages consumed and processed
- âœ… Running average calculated and displayed
- âœ… Failed messages retried automatically
- âœ… Permanently failed messages in DLQ
- âœ… All visible in Kafka UI

This was implemented by EG/2020/4077- Morais MNS